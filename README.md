# Bias in ChatGPT’s Educational Responses: A Data-Driven Visualization
## Abstract
This project analyzes biases in academic responses generated by ChatGPT, aiming to uncover hidden trends in AI’s educational outputs. It collects and categorizes biases—such as subjective, cultural, gender, and language bias—from ChatGPT’s responses to various educational prompts. The results are visualized using Tableau to highlight these patterns. The project offers insights and recommendations to reduce biases, promoting fairness, accuracy, and objectivity in AI-powered educational tools.
## Introduction
AI has transformed education, with ChatGPT becoming a widely used tool for academic purposes. However, since large language models (LLMs) are trained on diverse datasets, they may carry hidden biases. These biases can affect fairness and accuracy in educational settings.
This project explores bias patterns in ChatGPT’s educational responses through data analysis. We focus on key bias types, including:

- 🎯 **Gender bias:** Favoring certain majors by gender.
- 😊 **Sentiment bias:** Skewed positive or negative feedback.
- 🌍 **Racial bias:** Differing responses based on race.
- 🧠 **Cognitive bias:** Errors due to biased training data.
- 💰 **Socioeconomic bias:** Bias against lower-income groups or schools.

Our goal is to analyze these biases and propose solutions to make AI-based educational tools more fair and objective.
We collected datasets from these studies, covering various educational tasks, such as:

- Essay grading
- Academic feedback
- College and major recommendations
- Predicted salary and costs

We compiled and reorganized this data in Excel for analysis, focusing on key bias indicators. Then, we visualized the results using Tableau (with column and circle charts) to highlight the bias patterns clearly.

## Discussion
**1. Demographic Bias**
Our analysis found that ChatGPT shows bias when grading identical essays based on demographic cues like school type or socioeconomic status. It also recommended STEM majors at different rates based on race, potentially influencing students’ future decisions. Although some differences in predicted salaries and college costs were observed, they were not statistically significant.
**2. Sentiment Bias**
ChatGPT shows a strong tendency toward positive feedback, often avoiding negative responses. While this can create a supportive tone, it may limit constructive criticism and reduce feedback quality compared to instructors' more balanced evaluations.
**3. Cognitive Bias**
ChatGPT performs well on low-level “understanding” questions but struggles with higher-level “application” questions. This limits its effectiveness in assisting with complex academic tasks.
## Conclusion and Future Work

Key Insights:
Biases exist in ChatGPT’s educational responses—especially in demographic, sentiment, and cognitive aspects—which may influence student outcomes and reinforce inequalities.

Contribution:
This study highlights implicit risks in using ChatGPT in education, encouraging more responsible and cautious use of AI tools in learning environments.

Strengths & Limitations:
We synthesized data from multiple studies for a broad perspective but were limited to secondary data. Future work could involve generating new data using original prompts to assess bias further.

Recommendations:
To reduce bias, AI models should be refined through broader, more diverse datasets and stricter fairness testing, ensuring more equitable educational responses.
